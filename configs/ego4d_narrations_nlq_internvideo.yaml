dataset_name: ego4d
devices: cuda
train_split: ['training']
val_split: ['validation']
dataset: {
  json_file: ./ego4d_data/ego4d_nlq_v2_ori_data/nlq_val.json,
  train_jsonl_file: /s1_md0/leiji/v-zhijian/ego4d_nlq_cvpr_2023_data/ego4d_data_narration/format_unique_pretrain_data_v2.jsonl,
  val_jsonl_file: ./ego4d_data/ego4d_nlq_val_v2.jsonl,
  video_feat_dir: /s1_md0/leiji/v-zhijian/ego4d_data_2023/ego4d_lmdb/em_egovlp+internvideo_visual_features_1.87fps,
  text_feat_dir: /s1_md0/leiji/v-zhijian/ego4d_nlq_cvpr_2023_data/offline_lmdb/em_narration_clip_token_features,
  val_text_feat_dir: /s1_md0/leiji/v-zhijian/ego4d_nlq_cvpr_2023_data/offline_lmdb/nlq_v2_clip_token_features,
  num_classes: 1,
  input_vid_dim: 2304,
  input_txt_dim: 512,
  feat_stride: 16.043,
  num_frames: 16.043,
  default_fps: 30,
  max_seq_len: 2560,
  enable_temporal_jittering: True,
}
model: {
  fpn_type: identity,
  max_buffer_len_factor: 4.0,
  n_mha_win_size: 9,
  backbone_arch: [2, 4, 4, 0, 6],
  # shrink the model for reduced input feature channels
  n_head: 4,
  embd_dim: 384,
  fpn_dim: 384,
  head_dim: 384,
  use_abs_pe: True,
  regression_range: [[0, 4], [2, 8], [4, 16], [8, 32], [16, 64], [32, 128],[64, 10000]],
}
opt: {
  learning_rate: 0.00005,
  epochs: 6,
  warmup_epochs: 4,
  weight_decay: 0.05,
}
loader: {
  batch_size: 4,
}
train_cfg: {
  init_loss_norm: 200,
  clip_grad_l2norm: 1.0,
  cls_prior_prob: 0.01,
  center_sample: radius,
  center_sample_radius: 1.5,
  label_smoothing: 0.1,
  droppath: 0.1,
  loss_weight: 1.0,
}
test_cfg: {
  voting_thresh: 0.9,
  pre_nms_topk: 2000,
  # max of 50 predictions per video
  max_seg_num: 50,
  min_score: 0.001,
  nms_sigma : 0.75,
  duration_thresh: 0.001,
}
output_folder: ./ckpt/
